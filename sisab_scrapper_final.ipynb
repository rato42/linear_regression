{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4eb42c61",
   "metadata": {},
   "source": [
    "# Scrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bef2f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "CID_CODES = [\n",
    "\t\"F00\", \"F000\", \"F001\", \"F002\", \"F009\", \"F01\",\n",
    "\t\"F010\", \"F011\", \"F012\", \"F013\", \"F018\",\n",
    "\t\"F019\", \"F02\", \"F020\", \"F021\", \"F022\", \"F023\",\n",
    "\t\"F024\", \"F028\", \"F03\", \"F04\", \"F05\", \"F050\",\n",
    "\t\"F051\", \"F058\", \"F059\", \"F06\", \"F060\", \"F061\",\n",
    "\t\"F062\", \"F063\", \"F064\", \"F065\", \"F066\",\n",
    "\t\"F067\", \"F068\", \"F069\", \"F07\", \"F070\", \"F071\",\n",
    "\t\"F072\", \"F078\", \"F079\", \"F09\", \"F20\", \"F200\",\n",
    "\t\"F201\", \"F202\", \"F203\", \"F204\", \"F205\",\n",
    "\t\"F206\", \"F208\", \"F209\", \"F21\", \"F22\", \"F220\",\n",
    "\t\"F228\", \"F229\", \"F23\", \"F230\", \"F231\", \"F232\",\n",
    "\t\"F233\", \"F238\", \"F239\", \"F24\", \"F25\", \"F250\",\n",
    "\t\"F251\", \"F252\", \"F258\", \"F259\", \"F28\", \"F29\",\n",
    "\t\"F30\", \"F300\", \"F301\", \"F302\", \"F308\", \"F309\",\n",
    "\t\"F31\", \"F310\", \"F311\", \"F312\", \"F313\", \"F314\",\n",
    "\t\"F315\", \"F316\", \"F317\", \"F318\", \"F319\", \"F32\",\n",
    "\t\"F320\", \"F321\", \"F322\", \"F323\", \"F328\",\n",
    "\t\"F329\", \"F33\", \"F330\", \"F331\", \"F332\", \"F333\",\n",
    "\t\"F334\", \"F338\", \"F339\", \"F34\", \"F340\", \"F341\",\n",
    "\t\"F348\", \"F349\", \"F38\", \"F380\", \"F381\", \"F388\",\n",
    "\t\"F39\", \"F40\", \"F400\", \"F401\", \"F402\", \"F408\",\n",
    "\t\"F409\", \"F41\", \"F410\", \"F411\", \"F412\", \"F413\",\n",
    "\t\"F418\", \"F419\", \"F42\", \"F420\", \"F421\", \"F422\",\n",
    "\t\"F428\", \"F429\", \"F43\", \"F430\", \"F431\", \"F432\",\n",
    "\t\"F438\", \"F439\", \"F44\", \"F440\", \"F441\", \"F442\",\n",
    "\t\"F443\", \"F444\", \"F445\", \"F446\", \"F447\",\n",
    "\t\"F448\", \"F449\", \"F45\", \"F450\", \"F451\", \"F452\",\n",
    "\t\"F453\", \"F454\", \"F458\", \"F459\", \"F48\", \"F480\",\n",
    "\t\"F481\", \"F488\", \"F489\", \"F50\", \"F500\", \"F501\",\n",
    "\t\"F502\", \"F503\", \"F504\", \"F505\", \"F508\",\n",
    "\t\"F509\", \"F51\", \"F510\", \"F511\", \"F512\", \"F513\",\n",
    "\t\"F514\", \"F515\", \"F518\", \"F519\", \"F52\", \"F520\",\n",
    "\t\"F521\", \"F522\", \"F523\", \"F524\", \"F525\",\n",
    "\t\"F526\", \"F527\", \"F528\", \"F529\", \"F53\", \"F530\",\n",
    "\t\"F531\", \"F538\", \"F539\", \"F54\", \"F55\", \"F59\",\n",
    "\t\"F60\", \"F600\", \"F601\", \"F602\", \"F603\", \"F604\",\n",
    "\t\"F605\", \"F606\", \"F607\", \"F608\", \"F609\", \"F61\",\n",
    "\t\"F62\", \"F620\", \"F621\", \"F628\", \"F629\", \"F63\",\n",
    "\t\"F630\", \"F631\", \"F632\", \"F633\", \"F638\",\n",
    "\t\"F639\", \"F64\", \"F640\", \"F641\", \"F642\", \"F648\",\n",
    "\t\"F649\", \"F65\", \"F650\", \"F651\", \"F652\", \"F653\",\n",
    "\t\"F654\", \"F655\", \"F656\", \"F658\", \"F659\", \"F66\",\n",
    "\t\"F660\", \"F661\", \"F662\", \"F668\", \"F669\", \"F68\",\n",
    "\t\"F680\", \"F681\", \"F688\", \"F69\", \"F70\", \"F700\",\n",
    "\t\"F701\", \"F708\", \"F709\", \"F71\", \"F710\", \"F711\",\n",
    "\t\"F718\", \"F719\", \"F72\", \"F720\", \"F721\", \"F728\",\n",
    "\t\"F729\", \"F73\", \"F730\", \"F731\", \"F738\", \"F739\",\n",
    "\t\"F78\", \"F780\", \"F781\", \"F788\", \"F789\", \"F79\",\n",
    "\t\"F790\", \"F791\", \"F798\", \"F799\", \"F80\", \"F800\",\n",
    "\t\"F801\", \"F802\", \"F803\", \"F808\", \"F809\", \"F81\",\n",
    "\t\"F810\", \"F811\", \"F812\", \"F813\", \"F818\",\n",
    "\t\"F819\", \"F82\", \"F83\", \"F84\", \"F840\", \"F841\",\n",
    "\t\"F842\", \"F843\", \"F844\", \"F845\", \"F848\",\n",
    "\t\"F849\", \"F88\", \"F89\", \"F90\", \"F900\", \"F901\",\n",
    "\t\"F908\", \"F909\", \"F91\", \"F910\", \"F911\", \"F912\",\n",
    "\t\"F913\", \"F918\", \"F919\", \"F92\", \"F920\", \"F928\",\n",
    "\t\"F929\", \"F93\", \"F930\", \"F931\", \"F932\", \"F933\",\n",
    "\t\"F938\", \"F939\", \"F94\", \"F940\", \"F941\", \"F942\",\n",
    "\t\"F948\", \"F949\", \"F95\", \"F950\", \"F951\", \"F952\",\n",
    "\t\"F958\", \"F959\", \"F98\", \"F980\", \"F981\", \"F982\",\n",
    "\t\"F983\", \"F984\", \"F985\", \"F986\", \"F988\",\n",
    "\t\"F989\", \"F99\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc3070d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from selenium.webdriver.support.ui import Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0f29c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cid_string(cid, suffixo = \"-1\"):\n",
    "    \"\"\"\n",
    "    Cria uma string CID formatada para ser usada no payload do POST.\n",
    "    \"\"\"\n",
    "    cid_string = cid + suffixo\n",
    "    return cid_string\n",
    "\n",
    "def populate_cid_list(codes):\n",
    "\t\"\"\"\n",
    "\tPreenche a lista CID_LIST com os códigos CID formatados.\n",
    "\t\"\"\"\n",
    "\tcid_list = []\n",
    "\tfor code in codes:\n",
    "\t\tcid_list.append(create_cid_string(code))\n",
    "\treturn cid_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48d8c475",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Helper Functions\n",
    "\n",
    "def select_option_by_value(driver, select_xpath, value, timeout=50):\n",
    "\ttry:\n",
    "\t\tselect_element = WebDriverWait(driver, timeout).until(\n",
    "\t\t\tEC.element_to_be_clickable((By.XPATH, select_xpath))\n",
    "\t\t)\n",
    "\t\tselect = Select(select_element)\n",
    "\t\tselect.select_by_value(value)\n",
    "\t\t#print(f\"Selecionado valor '{value}' em '{select_xpath}'\")\n",
    "\t\treturn True\n",
    "\texcept Exception as e:\n",
    "\t\tprint(f\"Erro ao selecionar valor '{value}': {e}\")\n",
    "\t\treturn False\n",
    "\t\n",
    "def criar_lista_competencias_por_ano(ano):\n",
    "    competencias = []\n",
    "    for mes in range(1, 13):\n",
    "        competencia = f\"{ano}{mes:02}\"\n",
    "        competencias.append(competencia)\n",
    "    return competencias\n",
    "\n",
    "def create_script_string(script, arg=None, arg_as_string = True):\n",
    "    \"\"\"\n",
    "    Cria uma string de script JavaScript para execução.\n",
    "    \"\"\"\n",
    "    script_str = None\n",
    "    if arg:\n",
    "        if arg_as_string:\n",
    "            script_str = f\"{script}('{arg}')\"\n",
    "        else:\n",
    "            script_str = f\"{script}({arg})\"\n",
    "    else:\n",
    "        script_str = f\"{script}()\"\n",
    "    #print(\"script_str = \", script_str)\n",
    "    return script_str\n",
    "\n",
    "def exec_script(driver, script, arg=None, arg_as_string = True):\n",
    "    \"\"\"\n",
    "    Executa um script JavaScript no contexto da página atual.\n",
    "    \"\"\"\n",
    "    script_string = create_script_string(script, arg, arg_as_string)\n",
    "        \n",
    "    return driver.execute_script(script_string)\n",
    "\n",
    "def ExecuteCIDfilters(driver, cid_list):\n",
    "    for cid in cid_list:\n",
    "        exec_script(driver, 'addCid', cid)\n",
    "        #time.sleep(0.01)\n",
    "        #print(f\"Adicionando CID: {cid}\")\n",
    "    return True\n",
    "\n",
    "\n",
    "def ativar_checkbox_por_valor(driver, container_xpath, valor):\n",
    "\t\"\"\"\n",
    "\tAtiva o checkbox com o valor especificado dentro de um contêiner identificado por XPath.\n",
    "\n",
    "\tParâmetros:\n",
    "\t- driver: instância do WebDriver\n",
    "\t- container_xpath: XPath do contêiner que contém os checkboxes\n",
    "\t- valor: valor do atributo 'value' do checkbox a ser ativado\n",
    "\t\"\"\"\n",
    "\ttry:\n",
    "\t\tcontainer = driver.find_element(By.XPATH, container_xpath)\n",
    "\t\tcheckboxes = container.find_elements(By.XPATH, \".//input[@type='checkbox']\")\n",
    "\n",
    "\t\tfor checkbox in checkboxes:\n",
    "\t\t\tif checkbox.get_attribute(\"value\") == valor:\n",
    "\t\t\t\tif not checkbox.is_selected():\n",
    "\t\t\t\t\tcheckbox.click()\n",
    "\t\t\t\t\t#print(f\"Checkbox '{valor}' ativado.\")\n",
    "\t\t\t\t#else:\n",
    "\t\t\t\t\t#print(f\"Checkbox '{valor}' já estava ativado.\")\n",
    "\t\t\t\treturn True\n",
    "\n",
    "\t\tprint(f\"Checkbox com valor '{valor}' não encontrado.\")\n",
    "\t\treturn False\n",
    "\texcept Exception as e:\n",
    "\t\tprint(f\"Erro ao ativar checkbox '{valor}': {e}\")\n",
    "\t\treturn False\n",
    "      \n",
    "def AtivarListaDeCheckBoxes(driver, lista_checkboxes, dropdown_xpath, container_xpath):\n",
    "    drop_button = WebDriverWait(driver, 50).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, dropdown_xpath))\n",
    "    )\n",
    "    actions = ActionChains(driver)\n",
    "    actions.move_to_element(drop_button).click().perform()\n",
    "    WebDriverWait(driver, 50).until(\n",
    "        EC.visibility_of_element_located((By.XPATH, container_xpath))\n",
    "    )\n",
    "    for checkbox in lista_checkboxes:\n",
    "        ativar_checkbox_por_valor(driver, container_xpath, checkbox)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b07e621",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ARGS = {\n",
    "    'ano_range': [2016, 2024],\n",
    "    #\"ano\": 2024,\n",
    "    \"cid_list\": populate_cid_list(CID_CODES),\n",
    "    'linha': \"CID\",\n",
    "    'coluna': \"NU_COMPETENCIA\",\n",
    "    'ug': \"estado\",\n",
    "    'uf': \"43\",\n",
    "    'tpProducao' : \"4\",\n",
    "    #'municipios': [\"431490\"],\n",
    "    'estados': [\"RS\"],\n",
    "    'headless_browser': False,\n",
    "}\n",
    "JOIN_ARGS = {\n",
    "    'joinby_col': 'CIAP/CID',\n",
    "    \"perform_join\": True,          # Join multiple DataFrames into one\n",
    "    \"extract_code\": True,          # Extract codes (e.g., CID codes) from a specified column\n",
    "    \"group_and_sum\": True,         # Group the data by CID groups and sum the values\n",
    "    \"convert_labels\": True,        # Convert column labels (e.g., month names) into datetime objects\n",
    "    \"perform_grand_total\": True,   # Add a row with the sum of all numeric columns\n",
    "    \"save_to_excel\": True          # Save the final processed DataFrame to an Excel file\n",
    "}\n",
    "\n",
    "ARGS = {\n",
    "\n",
    "    'ano_range': [2024, 2024],\n",
    "    #\"ano\": 2024,\n",
    "    \"cid_list\": [],#populate_cid_list(CID_CODES),\n",
    "    'linha': \"BRASIL\",\n",
    "    'coluna': \"NU_COMPETENCIA\",\n",
    "    'ug': \"estado\",\n",
    "    'uf': \"43\",\n",
    "    'tpProducao' : \"4\",\n",
    "    #'municipios': [\"431490\"],\n",
    "    'estados': [\"RS\"],\n",
    "    'headless_browser': False,\n",
    "}\n",
    "\n",
    "JOIN_ARGS = {\n",
    "    'joinby_col': \"Brasil\",\n",
    "    \"perform_join\": True,          # Join multiple DataFrames into one\n",
    "    \"extract_code\": False,          # Extract codes (e.g., CID codes) from a specified column\n",
    "    \"group_and_sum\": False,         # Group the data by CID groups and sum the values\n",
    "    \"convert_labels\": True,        # Convert column labels (e.g., month names) into datetime objects\n",
    "    \"perform_grand_total\": False,   # Add a row with the sum of all numeric columns\n",
    "    \"save_to_excel\": True          # Save the final processed DataFrame to an Excel file\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ec4c307",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(args, url, download_dir):\n",
    "    DROPDOWN_BUTTON_PATH = \"/html/body/div[2]/div/section[2]/span/form/div[3]/div[1]/div/div[2]/div[2]/div[5]/div/div/div[2]/button\"\n",
    "    CSV_BUTTON_PATH = \"/html/body/div[2]/div/section[2]/span/form/div[3]/div[1]/div/div[2]/div[2]/div[5]/div/div/div[2]/ul/li[2]/a\"\n",
    "    \n",
    "    CID_CIAP_ADD = '//*[@id=\"btnAddCid\"]'\n",
    "    CID_CIAP_SELECTION = \"/html/body/div[2]/div/section[2]/span/form/div[1]/div/div/div[2]/div/div/div/div[2]/div/table/tbody\"\n",
    "    CONCLUIR_CID_CIAP_SELECTION = '/html/body/div[2]/div/section[2]/span/form/div[1]/div/div/div[2]/button[2]'\n",
    "    \n",
    "    COMPETENCIA_DROPDOWN_BUTTON_PATH = '/html/body/div[2]/div/section[2]/span/form/div[3]/div[1]/div/div[2]/div[2]/div[2]/div/div[2]/span/div/button'\n",
    "    COMPETENCIA_CHECKBOX_WRAPPER = \"/html/body/div[2]/div/section[2]/span/form/div[3]/div[1]/div/div[2]/div[2]/div[2]/div/div[2]/span/div/ul\"\n",
    "    \n",
    "    TIPO_PRODUCAO = '//*[@id=\"tpProducao\"]'\n",
    "    LINHA_SELECT = '//*[@id=\"selectLinha\"]'\n",
    "    COLUNA_SELECT = '//*[@id=\"selectcoluna\"]'\n",
    "    UG_SELECT = '//*[@id=\"unidGeo\"]'\n",
    "    UF_SELECT = '//*[@id=\"estadoMunicipio\"]'\n",
    "    \n",
    "    UG_DROPDOWN_BUTTON_PATH = '/html/body/div[2]/div/section[2]/span/form/div[3]/div[1]/div/div[2]/div[2]/div[1]/div/div[2]/span/div/button'\n",
    "    UG_CHECKBOX_WRAPPER = '/html/body/div[2]/div/section[2]/span/form/div[3]/div[1]/div/div[2]/div[2]/div[1]/div/div[2]/span/div/ul'\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    # Cria o diretório de download se ele não existir\n",
    "    if not os.path.exists(download_dir):\n",
    "        os.makedirs(download_dir)\n",
    "    \n",
    "    # Configurações do Chrome headless (sem abrir janela)\n",
    "    options = Options()\n",
    "    if args['headless_browser']:\n",
    "        options.add_argument(\"--headless=new\")\n",
    "    \n",
    "    # Configura o caminho de download\n",
    "    prefs = {\"download.default_directory\": download_dir}\n",
    "    options.add_experimental_option(\"prefs\", prefs)\n",
    "    \n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    print(driver)\n",
    "    try:\n",
    "        # Acessa a página\n",
    "        \n",
    "        driver.get(url)\n",
    "\n",
    "        # Espera o JS carregar\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        wait.until(EC.presence_of_element_located((By.NAME, \"javax.faces.ViewState\")))\n",
    "\n",
    "        ##################################################################################\n",
    "\n",
    "        select_option_by_value(driver, LINHA_SELECT, args['linha'])\n",
    "        time.sleep(1)\n",
    "        select_option_by_value(driver, COLUNA_SELECT, args['coluna'])\n",
    "        time.sleep(1)\n",
    "        select_option_by_value(driver, UG_SELECT, args['ug'])\n",
    "        time.sleep(1)\n",
    "        select_option_by_value(driver, TIPO_PRODUCAO, args['tpProducao'])\n",
    "        time.sleep(1)\n",
    "\n",
    "\n",
    "        AtivarListaDeCheckBoxes(driver, criar_lista_competencias_por_ano(args['ano']), COMPETENCIA_DROPDOWN_BUTTON_PATH, COMPETENCIA_CHECKBOX_WRAPPER)\n",
    "        time.sleep(1)\n",
    "\n",
    "        ug_dropdown_select_arg = args['municipios'] if args['ug'] == \"municipio\" else args['estados'] if args['ug'] == 'estado' else None\n",
    "\n",
    "        if ug_dropdown_select_arg:\n",
    "            if args['ug'] == \"municipio\":\n",
    "                select_option_by_value(driver, UF_SELECT, args['uf'])\n",
    "                time.sleep(1)\n",
    "            AtivarListaDeCheckBoxes(driver,ug_dropdown_select_arg, UG_DROPDOWN_BUTTON_PATH, UG_CHECKBOX_WRAPPER)\n",
    "            time.sleep(1)\n",
    "\n",
    "\n",
    "\n",
    "        ### CID CIAP\n",
    "        cid_Ciap = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, CID_CIAP_ADD))\n",
    "        )\n",
    "        cid_Ciap.click()\n",
    "        wait.until(EC.presence_of_element_located((By.XPATH, CID_CIAP_SELECTION)))\n",
    "        ExecuteCIDfilters(driver, args['cid_list'])\n",
    "        cid_Ciap_conclude = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, CONCLUIR_CID_CIAP_SELECTION))\n",
    "        )\n",
    "        cid_Ciap_conclude.click()\n",
    "        time.sleep(1)\n",
    "\n",
    "        # Clica no botão de download (exportar)\n",
    "        dropdown_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, DROPDOWN_BUTTON_PATH))\n",
    "        )\n",
    "        dropdown_button.click()\n",
    "        # Espera o dropdown aparecer\n",
    "        wait.until(EC.visibility_of_element_located((By.XPATH, \"/html/body/div[2]/div/section[2]/span/form/div[3]/div[1]/div/div[2]/div[2]/div[5]/div/div/div[2]/ul\")))\n",
    "        # Agora, localiza a opção \"Excel\" no dropdown\n",
    "        csv_opt_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, CSV_BUTTON_PATH))\n",
    "        )\n",
    "        time.sleep(1)\n",
    "        # Clica na opção csv para baixar o arquivo\n",
    "        csv_opt_button.click()\n",
    "        ###################################################################\n",
    "\n",
    "        preffix = 'scrapped_relatorio_'\n",
    "        file_name = f\"{preffix}{args['ano']}.csv\"  # Nome do arquivo desejado\n",
    "        temp_file_path = os.path.join(download_dir, file_name + \".crdownload\")\n",
    "        final_file_path = os.path.join(download_dir, file_name)\n",
    "\n",
    "        #while os.path.exists(temp_file_path):  # Espera o arquivo temporário desaparecer\n",
    "        #    time.sleep(1)\n",
    "        \n",
    "        def check_temp_file_exists():\n",
    "            for file in os.listdir(download_dir):\n",
    "                if file.endswith(\".tmp\"):\n",
    "                    return True\n",
    "            return False\n",
    "        \n",
    "        while check_temp_file_exists():  # Espera o arquivo temporário desaparecer\n",
    "            time.sleep(1)\n",
    "\n",
    "        # Renomeia o arquivo baixado\n",
    "        #original_file_name = url.split('/')[-1].split('.')[0]\n",
    "\n",
    "\n",
    "        for file in os.listdir(download_dir):\n",
    "            if file.endswith(\".csv\") and not file.startswith(preffix):\n",
    "                final_file_path = os.path.join(download_dir, file_name)\n",
    "                source_file_path = os.path.join(download_dir, file)\n",
    "                \n",
    "                # Verifica se o arquivo de destino já existe\n",
    "                if os.path.exists(final_file_path):\n",
    "                    print(f\"Arquivo {final_file_path} já existe. Sobrescrevendo...\")\n",
    "                    os.remove(final_file_path)  # Remove o arquivo existente\n",
    "                \n",
    "                os.rename(source_file_path, final_file_path)\n",
    "                print(f\"Arquivo salvo como: {final_file_path}\")\n",
    "                break\n",
    "\n",
    "            \n",
    "    finally:\n",
    "        # Fecha o driver\n",
    "        driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbb33d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<selenium.webdriver.chrome.webdriver.WebDriver (session=\"7f0a062d3731c6cc475dbac68512c2c6\")>\n"
     ]
    },
    {
     "ename": "InvalidSessionIdException",
     "evalue": "Message: invalid session id: session deleted as the browser has closed the connection\nfrom disconnected: Unable to receive message from renderer\n  (Session info: chrome=135.0.7049.114)\nStacktrace:\n\tGetHandleVerifier [0x00007FF6D450EFA5+77893]\n\tGetHandleVerifier [0x00007FF6D450F000+77984]\n\t(No symbol) [0x00007FF6D42D91BA]\n\t(No symbol) [0x00007FF6D42C65CC]\n\t(No symbol) [0x00007FF6D42C62BA]\n\t(No symbol) [0x00007FF6D42C3F67]\n\t(No symbol) [0x00007FF6D42C473C]\n\t(No symbol) [0x00007FF6D42C3056]\n\t(No symbol) [0x00007FF6D42E686E]\n\t(No symbol) [0x00007FF6D438B1AF]\n\t(No symbol) [0x00007FF6D435712A]\n\t(No symbol) [0x00007FF6D437F07F]\n\t(No symbol) [0x00007FF6D4356F03]\n\t(No symbol) [0x00007FF6D4320328]\n\t(No symbol) [0x00007FF6D4321093]\n\tGetHandleVerifier [0x00007FF6D47C7B6D+2931725]\n\tGetHandleVerifier [0x00007FF6D47C2132+2908626]\n\tGetHandleVerifier [0x00007FF6D47E00F3+3031443]\n\tGetHandleVerifier [0x00007FF6D45291EA+184970]\n\tGetHandleVerifier [0x00007FF6D453086F+215311]\n\tGetHandleVerifier [0x00007FF6D4516EC4+110436]\n\tGetHandleVerifier [0x00007FF6D4517072+110866]\n\tGetHandleVerifier [0x00007FF6D44FD479+5401]\n\tBaseThreadInitThunk [0x00007FF9E98B259D+29]\n\tRtlUserThreadStart [0x00007FF9EAF0AF38+40]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidSessionIdException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ano \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(ARGS[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mano_range\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m], ARGS[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mano_range\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):    \n\u001b[0;32m      9\u001b[0m     args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mano\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m ano\n\u001b[1;32m---> 10\u001b[0m     \u001b[43mdownload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcesso concluído.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[13], line 62\u001b[0m, in \u001b[0;36mdownload_data\u001b[1;34m(args, url, download_dir)\u001b[0m\n\u001b[0;32m     58\u001b[0m select_option_by_value(driver, TIPO_PRODUCAO, args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtpProducao\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     59\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 62\u001b[0m \u001b[43mAtivarListaDeCheckBoxes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriar_lista_competencias_por_ano\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mano\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCOMPETENCIA_DROPDOWN_BUTTON_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCOMPETENCIA_CHECKBOX_WRAPPER\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     65\u001b[0m ug_dropdown_select_arg \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmunicipios\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mug\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmunicipio\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mestados\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mug\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mestado\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[11], line 87\u001b[0m, in \u001b[0;36mAtivarListaDeCheckBoxes\u001b[1;34m(driver, lista_checkboxes, dropdown_xpath, container_xpath)\u001b[0m\n\u001b[0;32m     83\u001b[0m drop_button \u001b[38;5;241m=\u001b[39m WebDriverWait(driver, \u001b[38;5;241m50\u001b[39m)\u001b[38;5;241m.\u001b[39muntil(\n\u001b[0;32m     84\u001b[0m     EC\u001b[38;5;241m.\u001b[39melement_to_be_clickable((By\u001b[38;5;241m.\u001b[39mXPATH, dropdown_xpath))\n\u001b[0;32m     85\u001b[0m )\n\u001b[0;32m     86\u001b[0m actions \u001b[38;5;241m=\u001b[39m ActionChains(driver)\n\u001b[1;32m---> 87\u001b[0m \u001b[43mactions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmove_to_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdrop_button\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclick\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     88\u001b[0m WebDriverWait(driver, \u001b[38;5;241m50\u001b[39m)\u001b[38;5;241m.\u001b[39muntil(\n\u001b[0;32m     89\u001b[0m     EC\u001b[38;5;241m.\u001b[39mvisibility_of_element_located((By\u001b[38;5;241m.\u001b[39mXPATH, container_xpath))\n\u001b[0;32m     90\u001b[0m )\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m checkbox \u001b[38;5;129;01min\u001b[39;00m lista_checkboxes:\n",
      "File \u001b[1;32mc:\\Users\\Lucas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\selenium\\webdriver\\common\\action_chains.py:94\u001b[0m, in \u001b[0;36mActionChains.perform\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mperform\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Performs all stored actions.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 94\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mw3c_actions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Lucas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\selenium\\webdriver\\common\\actions\\action_builder.py:170\u001b[0m, in \u001b[0;36mActionBuilder.perform\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    168\u001b[0m         enc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactions\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(encoded)\n\u001b[0;32m    169\u001b[0m         device\u001b[38;5;241m.\u001b[39mactions \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 170\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW3C_ACTIONS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Lucas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:429\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    427\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 429\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    430\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\Lucas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:232\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    230\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mInvalidSessionIdException\u001b[0m: Message: invalid session id: session deleted as the browser has closed the connection\nfrom disconnected: Unable to receive message from renderer\n  (Session info: chrome=135.0.7049.114)\nStacktrace:\n\tGetHandleVerifier [0x00007FF6D450EFA5+77893]\n\tGetHandleVerifier [0x00007FF6D450F000+77984]\n\t(No symbol) [0x00007FF6D42D91BA]\n\t(No symbol) [0x00007FF6D42C65CC]\n\t(No symbol) [0x00007FF6D42C62BA]\n\t(No symbol) [0x00007FF6D42C3F67]\n\t(No symbol) [0x00007FF6D42C473C]\n\t(No symbol) [0x00007FF6D42C3056]\n\t(No symbol) [0x00007FF6D42E686E]\n\t(No symbol) [0x00007FF6D438B1AF]\n\t(No symbol) [0x00007FF6D435712A]\n\t(No symbol) [0x00007FF6D437F07F]\n\t(No symbol) [0x00007FF6D4356F03]\n\t(No symbol) [0x00007FF6D4320328]\n\t(No symbol) [0x00007FF6D4321093]\n\tGetHandleVerifier [0x00007FF6D47C7B6D+2931725]\n\tGetHandleVerifier [0x00007FF6D47C2132+2908626]\n\tGetHandleVerifier [0x00007FF6D47E00F3+3031443]\n\tGetHandleVerifier [0x00007FF6D45291EA+184970]\n\tGetHandleVerifier [0x00007FF6D453086F+215311]\n\tGetHandleVerifier [0x00007FF6D4516EC4+110436]\n\tGetHandleVerifier [0x00007FF6D4517072+110866]\n\tGetHandleVerifier [0x00007FF6D44FD479+5401]\n\tBaseThreadInitThunk [0x00007FF9E98B259D+29]\n\tRtlUserThreadStart [0x00007FF9EAF0AF38+40]\n"
     ]
    }
   ],
   "source": [
    "args = copy.deepcopy(ARGS)\n",
    "url = \"https://sisab.saude.gov.br/paginas/acessoRestrito/relatorio/federal/saude/RelSauProducao.xhtml\"\n",
    "download_dir = \"D:\\\\CodeStuff\\\\Stats\\\\colab_linear_regression\\\\linear_regression\\\\sisab_scrap_download\"#\"D:\\\\CodeStuff\\\\sisab\\\\ScrappedFiles\"#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for ano in range(ARGS['ano_range'][0], ARGS['ano_range'][1] + 1):    \n",
    "    args['ano'] = ano\n",
    "    download_data(args, url, download_dir)\n",
    "    time.sleep(1)\n",
    "print(\"Processo concluído.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed36387",
   "metadata": {},
   "source": [
    "# Joiner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d48fdaf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 9\n",
      "8 9\n",
      "8 9\n",
      "8 9\n",
      "8 9\n",
      "8 9\n",
      "8 9\n",
      "8 9\n",
      "8 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lucas\\AppData\\Local\\Temp\\ipykernel_13116\\1764006971.py:53: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')  # Converte para número, se possível\n",
      "C:\\Users\\Lucas\\AppData\\Local\\Temp\\ipykernel_13116\\1764006971.py:53: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')  # Converte para número, se possível\n",
      "C:\\Users\\Lucas\\AppData\\Local\\Temp\\ipykernel_13116\\1764006971.py:53: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')  # Converte para número, se possível\n",
      "C:\\Users\\Lucas\\AppData\\Local\\Temp\\ipykernel_13116\\1764006971.py:53: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')  # Converte para número, se possível\n",
      "C:\\Users\\Lucas\\AppData\\Local\\Temp\\ipykernel_13116\\1764006971.py:53: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')  # Converte para número, se possível\n",
      "C:\\Users\\Lucas\\AppData\\Local\\Temp\\ipykernel_13116\\1764006971.py:53: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')  # Converte para número, se possível\n",
      "C:\\Users\\Lucas\\AppData\\Local\\Temp\\ipykernel_13116\\1764006971.py:53: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')  # Converte para número, se possível\n",
      "C:\\Users\\Lucas\\AppData\\Local\\Temp\\ipykernel_13116\\1764006971.py:53: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')  # Converte para número, se possível\n",
      "C:\\Users\\Lucas\\AppData\\Local\\Temp\\ipykernel_13116\\1764006971.py:53: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')  # Converte para número, se possível\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "download_dir = \"D:\\\\CodeStuff\\\\Stats\\\\colab_linear_regression\\\\linear_regression\\\\sisab_scrap_download\"\n",
    "df_list = []\n",
    "PREFFIX = 'scrapped_relatorio_'  # Se for mudado, tem que mudar no scrapper também\n",
    "COLUMN_NAME = JOIN_ARGS['joinby_col']#'Brasil'#ARGS['joinby_col']#'CIAP/CID'#'Brasil'  # \n",
    "\n",
    "def get_start_and_end_lines_skip_metadata(file_path):\n",
    "    with open(file_path, 'r', encoding='latin1') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    start_line = None\n",
    "    end_line = None\n",
    "    n_brnco_lines = 0\n",
    "    for i, line in enumerate(lines):\n",
    "        if line == '\\n':\n",
    "            n_brnco_lines += 1\n",
    "        if n_brnco_lines == 2:\n",
    "            start_line = i + 1\n",
    "            break\n",
    "\n",
    "    n_brnco_lines = 0\n",
    "    for i, line in enumerate(lines[start_line:], start=start_line):\n",
    "        if line == '\\n':\n",
    "            n_brnco_lines += 1\n",
    "        if n_brnco_lines == 2:\n",
    "            end_line = i - 2\n",
    "            break\n",
    "    return start_line, end_line\n",
    "\n",
    "for file in os.listdir(download_dir):\n",
    "    if file.endswith(\".csv\") and file.startswith(PREFFIX):\n",
    "        file_path = os.path.join(download_dir, file)\n",
    "        \n",
    "        start_line, end_line = get_start_and_end_lines_skip_metadata(file_path)\n",
    "        print(start_line, end_line)\n",
    "        \n",
    "        # Lê o arquivo como texto\n",
    "        df = pd.read_csv(\n",
    "            file_path, \n",
    "            sep=';', \n",
    "            encoding='latin1', \n",
    "            skiprows=start_line, \n",
    "            nrows=end_line - start_line, \n",
    "            dtype=str  # Lê todas as colunas como texto\n",
    "        )\n",
    "        \n",
    "        # Remove os pontos e converte para inteiro\n",
    "        for col in df.columns:\n",
    "            df[col] = df[col].str.replace('.', '', regex=False).str.replace(',', '.', regex=False)\n",
    "            try:\n",
    "                df[col] = pd.to_numeric(df[col], errors='ignore')  # Converte para número, se possível\n",
    "            except ValueError:\n",
    "                pass\n",
    "        \n",
    "        df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "69fdf92c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Brasil",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "DEZ/2016",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "NOV/2016",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "OUT/2016",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "SET/2016",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "AGO/2016",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "JUL/2016",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "JUN/2016",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "MAI/2016",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ABR/2016",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "MAR/2016",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "FEV/2016",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "JAN/2016",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Unnamed: 13",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "230203a7-70bb-47a9-ae19-fdb5043e72d5",
       "rows": [
        [
         "0",
         "Nacional",
         "679637",
         "703820",
         "885950",
         "914467",
         "1038622",
         "885051",
         "998474",
         "860238",
         "697451",
         "883196",
         "627366",
         "567916",
         null
        ]
       ],
       "shape": {
        "columns": 14,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brasil</th>\n",
       "      <th>DEZ/2016</th>\n",
       "      <th>NOV/2016</th>\n",
       "      <th>OUT/2016</th>\n",
       "      <th>SET/2016</th>\n",
       "      <th>AGO/2016</th>\n",
       "      <th>JUL/2016</th>\n",
       "      <th>JUN/2016</th>\n",
       "      <th>MAI/2016</th>\n",
       "      <th>ABR/2016</th>\n",
       "      <th>MAR/2016</th>\n",
       "      <th>FEV/2016</th>\n",
       "      <th>JAN/2016</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nacional</td>\n",
       "      <td>679637</td>\n",
       "      <td>703820</td>\n",
       "      <td>885950</td>\n",
       "      <td>914467</td>\n",
       "      <td>1038622</td>\n",
       "      <td>885051</td>\n",
       "      <td>998474</td>\n",
       "      <td>860238</td>\n",
       "      <td>697451</td>\n",
       "      <td>883196</td>\n",
       "      <td>627366</td>\n",
       "      <td>567916</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Brasil  DEZ/2016  NOV/2016  OUT/2016  SET/2016  AGO/2016  JUL/2016  \\\n",
       "0  Nacional    679637    703820    885950    914467   1038622    885051   \n",
       "\n",
       "   JUN/2016  MAI/2016  ABR/2016  MAR/2016  FEV/2016  JAN/2016  Unnamed: 13  \n",
       "0    998474    860238    697451    883196    627366    567916          NaN  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7c85cbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'variaveis': ['Nacional', 'Nacional', 'Nacional', 'Nacional', 'Nacional', 'Nacional', 'Nacional', 'Nacional', 'Nacional']}\n"
     ]
    }
   ],
   "source": [
    "maindf_info = {\n",
    "    'variaveis': []\n",
    "}\n",
    "\n",
    "for i, df in enumerate(df_list):\n",
    "    if COLUMN_NAME in df.columns:  # Ensure the column exists\n",
    "        maindf_info['variaveis'].extend(df[COLUMN_NAME].unique())  # Add unique values from the column\n",
    "print(maindf_info)\n",
    "# Remove duplicates from the final list\n",
    "maindf_info['variaveis'] = list(set(maindf_info['variaveis']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "66529956",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def join_dfs(df_list):\n",
    "    # Step 1: Extract unique CIAP/CID values\n",
    "    maindf_info = {\n",
    "        'variaveis': []\n",
    "    }\n",
    "\n",
    "    for i, df in enumerate(df_list):\n",
    "        if COLUMN_NAME in df.columns:  # Ensure the column exists\n",
    "            maindf_info['variaveis'].extend(df[COLUMN_NAME].unique())  # Add unique values from the column\n",
    "\n",
    "    # Remove duplicates from the final list\n",
    "    unique_ciap_cid = list(set(maindf_info['variaveis']))\n",
    "\n",
    "    # Step 2: Create a new DataFrame with CIAP/CID as the index\n",
    "    result_df = pd.DataFrame(index=unique_ciap_cid)\n",
    "\n",
    "    # Step 3: Iterate through all DataFrames and append their columns\n",
    "    for i, df in enumerate(df_list):\n",
    "        if COLUMN_NAME in df.columns:  # Ensure the column exists\n",
    "            df = df.set_index(COLUMN_NAME)  # Set CIAP/CID as the index\n",
    "            for col in df.columns:  # Iterate through the columns\n",
    "                if col not in result_df.columns:\n",
    "                    result_df[col] = 0  # Initialize the column with 0\n",
    "                result_df[col] = result_df[col].add(df[col], fill_value=0)  # Add values, filling missing with 0\n",
    "\n",
    "    # Step 4: Reset the index if you want CIAP/CID as a column instead of the index\n",
    "    result_df.reset_index(inplace=True)\n",
    "    result_df.rename(columns={'index': COLUMN_NAME}, inplace=True)\n",
    "\n",
    "    # Fill any remaining NaN values with 0\n",
    "    result_df.fillna(0, inplace=True)\n",
    "\n",
    "    for col in result_df.columns[1:]:  # Skip the COLUMN_NAME column\n",
    "        result_df[col] = result_df[col].astype(int)\n",
    "\n",
    "\n",
    "    # Print the resulting DataFrame\n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "872aa863",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_code_from_parentheses(df, column_name=COLUMN_NAME, new_column_name='Code'):\n",
    "    \"\"\"\n",
    "    Extracts the code between parentheses from the specified column and adds it as a new column.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The DataFrame to process.\n",
    "    - column_name (str): The name of the column to extract the code from.\n",
    "    - new_column_name (str): The name of the new column to store the extracted codes.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The updated DataFrame with the new column.\n",
    "    \"\"\"\n",
    "    if column_name in df.columns:\n",
    "        # Use regex to extract the content between parentheses\n",
    "        df[new_column_name] = df[column_name].str.extract(r'\\((.*?)\\)')\n",
    "    else:\n",
    "        print(f\"Column '{column_name}' not found in the DataFrame.\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d95130df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_and_sum_by_cid_group(df, cid_grup_ref_df, cid_column='CID_code', value_columns=None):\n",
    "    \"\"\"\n",
    "    Groups the DataFrame by CID groups and sums the values.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The DataFrame containing the CID codes and values.\n",
    "    - cid_grup_ref_df (pd.DataFrame): The reference DataFrame mapping CID codes to groups.\n",
    "    - cid_column (str): The column in `df` containing the CID codes.\n",
    "    - value_columns (list): The columns in `df` to sum. If None, all numeric columns will be summed.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: A new DataFrame grouped by CID groups with summed values.\n",
    "    \"\"\"\n",
    "    # Merge the main DataFrame with the reference DataFrame to map CID codes to groups\n",
    "    merged_df = df.merge(cid_grup_ref_df, left_on=cid_column, right_on='cid_ind_cod', how='left')\n",
    "    #return merged_df\n",
    "    # Rename the column to avoid overwriting\n",
    "    #merged_df.rename(columns={cid_column: 'Original_CID_code'}, inplace=True)\n",
    "\n",
    "    # Replace CID codes with their group names\n",
    "    #merged_df['CID_group'] = merged_df['cid_grup_nome']\n",
    "\n",
    "    # Drop unnecessary columns from the merge\n",
    "    #merged_df.drop(['cid_grup_cod', 'cid_grup_nome', 'cid_ind_cod', 'Original_CID_code'], axis=1, inplace=True)\n",
    "\n",
    "    # Group by the CID group names and sum the values\n",
    "\n",
    "    if value_columns is None:\n",
    "        value_columns = merged_df.select_dtypes(include='number').columns  # Default to numeric columns\n",
    "    grouped_df = merged_df.groupby('cid_grup_nome')[value_columns].sum().reset_index()\n",
    "    grouped_df.drop(columns=['CID_code'], inplace=True, errors='ignore')\n",
    "\n",
    "    return grouped_df, merged_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "3fed65cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_column_labels_to_datetime(df):\n",
    "    \"\"\"\n",
    "    Converts column labels with Portuguese month names into datetime objects.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The DataFrame with column labels to convert.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The DataFrame with updated column labels.\n",
    "    \"\"\"\n",
    "    # Define a mapping for Portuguese month abbreviations to numbers\n",
    "    month_mapping = {\n",
    "        \"JAN\": \"01\", \"FEV\": \"02\", \"MAR\": \"03\", \"ABR\": \"04\", \"MAI\": \"05\", \"JUN\": \"06\",\n",
    "        \"JUL\": \"07\", \"AGO\": \"08\", \"SET\": \"09\", \"OUT\": \"10\", \"NOV\": \"11\", \"DEZ\": \"12\"\n",
    "    }\n",
    "\n",
    "    # Create a new dictionary for updated column labels\n",
    "    new_columns = {}\n",
    "    for col in df.columns:\n",
    "        try:\n",
    "            # Replace Portuguese month abbreviations with numbers\n",
    "            updated_col = col.upper()\n",
    "            for month, num in month_mapping.items():\n",
    "                updated_col = updated_col.replace(month, num)\n",
    "            # Convert to datetime if possible\n",
    "            new_columns[col] = pd.to_datetime(updated_col, format=\"%m/%Y\", errors=\"ignore\")\n",
    "        except Exception:\n",
    "            # If conversion fails, keep the original column name\n",
    "            new_columns[col] = col\n",
    "    df.rename(columns=new_columns, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "812d0979",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_grand_total_row(df):\n",
    "    \"\"\"\n",
    "    Adiciona uma linha ao DataFrame com a soma de todas as colunas numéricas.\n",
    "    A linha será chamada 'Grand Total'.\n",
    "    \"\"\"\n",
    "    # Calcula a soma de todas as colunas numéricas\n",
    "    total_row = df.select_dtypes(include='number').sum()\n",
    "    \n",
    "    # Adiciona a linha ao DataFrame\n",
    "    total_row[COLUMN_NAME] = \"Grand Total\"  # Define o nome da linha\n",
    "    df = pd.concat([df, pd.DataFrame([total_row])], ignore_index=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a8f42afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cid_grup_ref_df = pd.read_excel(\"D:\\\\CodeStuff\\\\sisab\\\\cid_f_grupos_referencia.xlsx\", engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "47d8ef33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dfs(\n",
    "\tdf_list,\n",
    "\tcid_grup_ref_df,\n",
    "\tcolumn_name,\n",
    "\toutput_file_path=None,\n",
    "\tperform_join=JOIN_ARGS['perform_join'],\n",
    "\textract_code=JOIN_ARGS['extract_code'],\n",
    "\tgroup_and_sum=JOIN_ARGS['group_and_sum'],\n",
    "\tconvert_labels=JOIN_ARGS['convert_labels'],\n",
    "\tperform_grand_total=JOIN_ARGS['perform_grand_total'],\n",
    "\tsave_to_excel=JOIN_ARGS['save_to_excel'],\n",
    "):\n",
    "\tresults = {}\n",
    "\n",
    "\t# Step 1: Join DataFrames\n",
    "\tif perform_join:\n",
    "\t\tjoined_df = join_dfs(df_list)\n",
    "\t\tresults['joined_df'] = joined_df\n",
    "\telse:\n",
    "\t\tjoined_df = df_list  # assume it's already joined or passed as a single df\n",
    "\n",
    "\t# Step 2: Extract code from parentheses\n",
    "\tif extract_code:\n",
    "\t\tcoded_df = extract_code_from_parentheses(joined_df, column_name=column_name, new_column_name='CID_code')\n",
    "\t\tresults['coded_df'] = coded_df\n",
    "\telse:\n",
    "\t\tcoded_df = joined_df\n",
    "\n",
    "\t# Step 3: Group and sum by CID group\n",
    "\tif group_and_sum:\n",
    "\t\tgrouped_df, test_grouped_df = group_and_sum_by_cid_group(\n",
    "\t\t\tcoded_df,\n",
    "\t\t\tcid_grup_ref_df,\n",
    "\t\t\tcid_column='CID_code',\n",
    "\t\t\tvalue_columns=None  # or coded_df.columns[1:] if needed\n",
    "\t\t)\n",
    "\t\tresults['grouped_df'] = grouped_df\n",
    "\t\tresults['test_grouped_df'] = test_grouped_df\n",
    "\telse:\n",
    "\t\tgrouped_df = coded_df\n",
    "\n",
    "\t# Step 4: Convert column labels to datetime\n",
    "\tif convert_labels:\n",
    "\t\tdated_df = convert_column_labels_to_datetime(grouped_df)\n",
    "\t\tresults['dated_df'] = dated_df\n",
    "\telse:\n",
    "\t\tdated_df = grouped_df\n",
    "\n",
    "\tif perform_grand_total:\n",
    "\t\tdated_df = add_grand_total_row(dated_df)\n",
    "\t\tresults['dated_df_with_grand_total'] = dated_df\n",
    "\telse:\t\n",
    "\t\tdated_df = dated_df\n",
    "\n",
    "\t# Step 5: Save to Excel\n",
    "\tif save_to_excel and output_file_path is not None:\n",
    "\t\tdated_df.to_excel(output_file_path, index=False, engine='openpyxl')\n",
    "\n",
    "\treturn results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b5dfcf6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lucas\\AppData\\Local\\Temp\\ipykernel_13116\\2596961310.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[col] = 0  # Initialize the column with 0\n",
      "C:\\Users\\Lucas\\AppData\\Local\\Temp\\ipykernel_13116\\2596961310.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[col] = 0  # Initialize the column with 0\n",
      "C:\\Users\\Lucas\\AppData\\Local\\Temp\\ipykernel_13116\\2596961310.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[col] = 0  # Initialize the column with 0\n",
      "C:\\Users\\Lucas\\AppData\\Local\\Temp\\ipykernel_13116\\2596961310.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[col] = 0  # Initialize the column with 0\n",
      "C:\\Users\\Lucas\\AppData\\Local\\Temp\\ipykernel_13116\\2596961310.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[col] = 0  # Initialize the column with 0\n",
      "C:\\Users\\Lucas\\AppData\\Local\\Temp\\ipykernel_13116\\2596961310.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[col] = 0  # Initialize the column with 0\n",
      "C:\\Users\\Lucas\\AppData\\Local\\Temp\\ipykernel_13116\\2596961310.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[col] = 0  # Initialize the column with 0\n",
      "C:\\Users\\Lucas\\AppData\\Local\\Temp\\ipykernel_13116\\2596961310.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[col] = 0  # Initialize the column with 0\n",
      "C:\\Users\\Lucas\\AppData\\Local\\Temp\\ipykernel_13116\\2596961310.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[col] = 0  # Initialize the column with 0\n",
      "C:\\Users\\Lucas\\AppData\\Local\\Temp\\ipykernel_13116\\2596961310.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df.reset_index(inplace=True)\n",
      "C:\\Users\\Lucas\\AppData\\Local\\Temp\\ipykernel_13116\\1379609063.py:26: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
      "  new_columns[col] = pd.to_datetime(updated_col, format=\"%m/%Y\", errors=\"ignore\")\n",
      "C:\\Users\\Lucas\\AppData\\Local\\Temp\\ipykernel_13116\\1379609063.py:26: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
      "  new_columns[col] = pd.to_datetime(updated_col, format=\"%m/%Y\", errors=\"ignore\")\n",
      "C:\\Users\\Lucas\\AppData\\Local\\Temp\\ipykernel_13116\\1379609063.py:26: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
      "  new_columns[col] = pd.to_datetime(updated_col, format=\"%m/%Y\", errors=\"ignore\")\n"
     ]
    }
   ],
   "source": [
    "output_file_path = \"D:\\\\CodeStuff\\\\Stats\\\\colab_linear_regression\\\\linear_regression\\\\sisab_scrap_download\\\\joined_files\\\\grouped_data.xlsx\"\n",
    "results = process_dfs(\n",
    "\tdf_list=df_list,\n",
    "\tcid_grup_ref_df=cid_grup_ref_df,\n",
    "\tcolumn_name=COLUMN_NAME,\n",
    "\toutput_file_path=output_file_path,\n",
    ")\n",
    "\n",
    "# Access any intermediate result\n",
    "grouped_df = results.get(\"grouped_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "da10dd97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\njoined_df = join_dfs(df_list)\\ncoded_df = extract_code_from_parentheses(joined_df, column_name=COLUMN_NAME, new_column_name=\\'CID_code\\')\\ngrouped_df, test_grouped_df = group_and_sum_by_cid_group(coded_df, cid_grup_ref_df, cid_column=\\'CID_code\\', value_columns=None)#coded_df.columns[1:])\\ngrouped_df\\ndated_df = convert_column_labels_to_datetime(grouped_df)\\n\\noutput_file_path = \"D:\\\\CodeStuff\\\\Stats\\\\colab_linear_regression\\\\linear_regression\\\\sisab_scrap_download\\\\joined_files\\\\grouped_data.xlsx\"\\n#joined_df.to_excel(\"test_grouped_df.xlsx\", index=False, engine=\\'openpyxl\\')\\ndated_df.to_excel(output_file_path, index=False, engine=\\'openpyxl\\')\\ngrouped_df\\n'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "joined_df = join_dfs(df_list)\n",
    "coded_df = extract_code_from_parentheses(joined_df, column_name=COLUMN_NAME, new_column_name='CID_code')\n",
    "grouped_df, test_grouped_df = group_and_sum_by_cid_group(coded_df, cid_grup_ref_df, cid_column='CID_code', value_columns=None)#coded_df.columns[1:])\n",
    "grouped_df\n",
    "dated_df = convert_column_labels_to_datetime(grouped_df)\n",
    "\n",
    "output_file_path = \"D:\\\\CodeStuff\\\\Stats\\\\colab_linear_regression\\\\linear_regression\\\\sisab_scrap_download\\\\joined_files\\\\grouped_data.xlsx\"\n",
    "#joined_df.to_excel(\"test_grouped_df.xlsx\", index=False, engine='openpyxl')\n",
    "dated_df.to_excel(output_file_path, index=False, engine='openpyxl')\n",
    "grouped_df\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
